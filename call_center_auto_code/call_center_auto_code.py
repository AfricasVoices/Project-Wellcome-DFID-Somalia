import argparse
import os
import time
from os import path
import hashlib
from dateutil.parser import isoparse
import jsonpickle
import datetime
import json

from core_data_modules.cleaners import swahili, Codes
from core_data_modules.traced_data import Metadata, TracedData
from core_data_modules.traced_data.io import TracedDataJsonIO, TracedDataCSVIO
from core_data_modules.util import IOUtils, PhoneNumberUuidTable


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Cleans the surveys and exports variables to Coda for "
                                                 "manual verification and coding")
    parser.add_argument("user", help="User launching this program, for use by TracedData Metadata")
    parser.add_argument("json_input_path", metavar="json-input-path",
                        help="Path to input file, containing a list of serialized TracedData objects as JSON")
    parser.add_argument("prev_coded_path", metavar="prev-coded-path",
                        help="Directory containing Coda files generated by a previous run of this pipeline stage. "
                             "New data will be appended to this file.")
    parser.add_argument("phone_uuid_table_path", metavar="phone-uuid-table-path",
                        help="JSON file containing an existing phone number <-> UUID lookup table.")
    parser.add_argument("json_output_path", metavar="json-output-path",
                        help="Path to a JSON file to write processed TracedData messages to")
    parser.add_argument("coded_output_path", metavar="coding-output-path",
                        help="Directory to write coding files to")
    parser.add_argument("flow_name", metavar="flow-name")

    args = parser.parse_args()
    user = args.user
    json_input_path = args.json_input_path
    prev_coded_path = args.prev_coded_path
    phone_uuid_table_path = args.phone_uuid_table_path
    json_output_path = args.json_output_path
    coded_output_path = args.coded_output_path
    flow_name = args.flow_name

    CONTROL_CODES = ["NA", "NC", "WS"]

    class CleaningPlan:
        def __init__(self, raw_field, clean_field, coda_name, cleaner, scheme_id):
            self.raw_field = raw_field
            self.clean_field = clean_field
            self.coda_name = coda_name
            self.cleaner = cleaner
            self.scheme_id = scheme_id

    cleaning_plans = {
        "call_center":
        [CleaningPlan("informationcc_raw_radio_q1_why", "informationcc_radio_q1_why_clean", "RadioQ1",
                     None, None),
        CleaningPlan("informationcc_raw_radio_q2_why", "informationcc_radio_q2_why_clean", "RadioQ2",
                     None, None)              
       ]    
    }

    cleaning_plan = cleaning_plans[flow_name]

    # Load phone number UUID table
    with open(phone_uuid_table_path, "r") as f:
        phone_uuids = PhoneNumberUuidTable.load(f)

    # Load data from JSON file
    with open(json_input_path, "r") as f:
        data = TracedDataJsonIO.import_json_to_traced_data_iterable(f)

    # Mark missing entries in the raw data as true missing
    for td in data:
        missing = dict()
        for plan in cleaning_plan:
            if td[plan.raw_field] == "n/a":
                missing[plan.raw_field] = Codes.TRUE_MISSING
        td.append_data(missing, Metadata(user, Metadata.get_call_location(), time.time()))

    # Exclude missing data
    for plan in cleaning_plan:
        data = [td for td in data if td[plan.raw_field] not in {Codes.TRUE_MISSING, Codes.SKIPPED, Codes.NOT_LOGICAL}]

    # Clean all responses, add MessageID and Labels
    for td in data:
        cleaned = dict()
        message_id = dict()
        labels = dict()
        for plan in cleaning_plan:
            hash_object = hashlib.sha256()
            hash_object.update(td[plan.raw_field].encode('utf-8'))
            message_id_string = hash_object.hexdigest()
            message_id_key = "{} MessageID".format(plan.raw_field)
            message_id[message_id_key] = message_id_string
            labels_key = "{} Labels".format(plan.raw_field)
            labels[labels_key] = []
           
        td.append_data(cleaned, Metadata(user, Metadata.get_call_location(), time.time()))
        td.append_data(message_id, Metadata(user, Metadata.get_call_location(), time.time()))
        td.append_data(labels, Metadata(user, Metadata.get_call_location(), time.time()))

    # Write json output
    IOUtils.ensure_dirs_exist_for_file(json_output_path)
    with open(json_output_path, "w") as f:
        TracedDataJsonIO.export_traced_data_iterable_to_json(data, f, pretty_print=True)
    
    # Output for manual verification + coding
    IOUtils.ensure_dirs_exist(coded_output_path)
    for plan in cleaning_plan:
        coded_output_file_path = path.join(coded_output_path, "{}.json".format(plan.coda_name))
        message_ids = list()
        messages_to_code = list()
        avf_phone_ids = list()
        all_messages = list()
        for td in data:
                output = dict()        
                output["Labels"] = td["{} Labels".format(plan.raw_field)]
                output["MessageID"] = td["{} MessageID".format(plan.raw_field)]
                output["Text"] = str(td[plan.raw_field])
                output["CreationDateTimeUTC"] = isoparse(td["start"]).isoformat()
                if output["MessageID"] not in message_ids:
                    messages_to_code.append(output)
                    message_ids.append(output["MessageID"])
                output["avf_phone_id"] = td["avf_phone_id"]
                if td["avf_phone_id"] not in avf_phone_ids:
                    all_messages.append(output)
                    avf_phone_ids.append(td["avf_phone_id"])
        with open(coded_output_file_path, "w") as f:
            jsonpickle.set_encoder_options("json", sort_keys=True)
            f.write(jsonpickle.dumps(messages_to_code))
            f.write("\n")
        